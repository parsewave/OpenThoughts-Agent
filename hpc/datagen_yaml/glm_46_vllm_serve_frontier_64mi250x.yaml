# GLM-4.6 AWQ on Frontier - 64 MI250X GPUs (16 nodes, 128 GCDs)
# Optimized for short walltime (2h max at <92 nodes)
#
# HARDWARE: OLCF Frontier - AMD MI250X GPUs
#   - 64 MI250X packages = 128 GCDs (Graphics Compute Dies)
#   - Each GCD has 64GB HBM2e
#   - 16 nodes x 4 MI250X/node x 2 GCDs/MI250X = 128 GCDs total
#
# MODEL: QuantTrio/GLM-4.6-AWQ (~23GB quantized)
#   - TP=4 for good parallelism on 64GB GCDs
#   - 16 replicas x TP=4 = 64 MI250X GPUs
#
# NOTE: ROCm-specific - no FP8 KV cache, no PPLX backend

engine:
  type: vllm_local
  model: QuantTrio/GLM-4.6-AWQ
  max_output_tokens: 16384
  healthcheck_interval: 300
  request_params:
    temperature: 1.0
    top_p: 0.01
  vllm_local: {}
backend:
  type: ray
  wait_for_endpoint: true
  tensor_parallel_size: 4
  pipeline_parallel_size: 1
  data_parallel_size: 16
  ray_cgraph_max_inflight_executions: 16
  healthcheck_max_attempts: 160
  healthcheck_retry_delay: 15
vllm_server:
  model_path: QuantTrio/GLM-4.6-AWQ
  num_replicas: 16
  tensor_parallel_size: 4
  pipeline_parallel_size: 1
  data_parallel_size: 16
  time_limit: '02:00:00'
  max_model_len: 65536
  max_num_seqs: 64
  gpu_memory_utilization: 0.85
  swap_space: 16
  enable_expert_parallel: true
  enable_auto_tool_choice: true
  tool_call_parser: glm45
  reasoning_parser: glm45
  trust_remote_code: true
  extra_args:
  - --dtype
  - bfloat16
  - --block-size
  - '16'
  - --enable-chunked-prefill
  - --max-num-partial-prefills
  - '1'
  - --enable-prefix-caching
  - --max-num-batched-tokens
  - '16384'

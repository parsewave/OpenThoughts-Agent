engine:
  type: vllm_local
  model: moonshotai/Kimi-K2-Thinking
  max_output_tokens: 8192
  healthcheck_interval: 300
  request_params:
    temperature: 1.0
    top_p: 0.01
  vllm_local: {}
backend:
  type: ray
  wait_for_endpoint: true
  tensor_parallel_size: 8
  pipeline_parallel_size: 1
  data_parallel_size: 1
  ray_cgraph_max_inflight_executions: 16
  healthcheck_max_attempts: 160
  healthcheck_retry_delay: 15
vllm_server:
  model_path: moonshotai/Kimi-K2-Thinking
  num_replicas: 1
  tensor_parallel_size: 8
  pipeline_parallel_size: 1
  data_parallel_size: 1
  time_limit: '48:00:00'
  max_model_len: 32768
  max_num_seqs: 16
  gpu_memory_utilization: 0.9
  swap_space: 32
  enable_expert_parallel: true
  enable_auto_tool_choice: true
  tool_call_parser: kimi_k2
  reasoning_parser: kimi_k2
  trust_remote_code: true
  extra_args:
  - --quantization
  - compressed-tensors
  - --kv-cache-dtype
  - fp8
  - --block-size
  - '16'
  - --enable-chunked-prefill
  - --max-num-partial-prefills
  - '1'
  - --enable-prefix-caching
  - --max-num-batched-tokens
  - '8192'
  - --all2all-backend
  - pplx
  - --cpu-offload-gb
  - '20'

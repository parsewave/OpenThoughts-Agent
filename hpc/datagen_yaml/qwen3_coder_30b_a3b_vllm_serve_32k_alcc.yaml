engine:
  type: vllm_local
  model: Qwen/Qwen3-Coder-30B-A3B-Instruct
  max_output_tokens: 8192
  healthcheck_interval: 300
  vllm_local: {}
backend:
  type: ray
  wait_for_endpoint: true
vllm_server:
  model_path: Qwen/Qwen3-Coder-30B-A3B-Instruct
  num_replicas: 1
  tensor_parallel_size: 4
  pipeline_parallel_size: 1
  data_parallel_size: 1
  time_limit: '48:00:00'
  max_model_len: 32768
  max_num_seqs: 32
  gpu_memory_utilization: 0.9
  swap_space: 8
  enable_expert_parallel: true
  trust_remote_code: true
  enable_auto_tool_choice: true
  tool_call_parser: qwen3_coder
  reasoning_parser: qwen3
  extra_args:
  - --dtype
  - bfloat16

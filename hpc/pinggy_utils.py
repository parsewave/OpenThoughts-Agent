"""Pinggy tunnel utilities for exposing local vLLM endpoints to cloud containers.

When running evals with cloud-based sandbox environments (Daytona, Modal) that
cannot reach the HPC cluster's private network, we use Pinggy to create a
public HTTPS tunnel to the local vLLM server.

Usage:
    from hpc.pinggy_utils import PinggyTunnel, PinggyConfig, needs_pinggy_tunnel

    if needs_pinggy_tunnel(agent_name, env_type):
        config = PinggyConfig(
            persistent_url="bjfqkhfxtx.a.pinggy.link",
            ssh_command="ssh -p 443 -R0:localhost:8000 ...",
        )
        with PinggyTunnel(config) as tunnel:
            # Use tunnel.public_endpoint instead of local vLLM endpoint
            endpoint = tunnel.public_endpoint  # https://bjfqkhfxtx.a.pinggy.link
"""

from __future__ import annotations

import os
import shlex
import signal
import subprocess
import time
from dataclasses import dataclass, field
from pathlib import Path
from typing import Optional, Dict, Any
import urllib.request
import urllib.error


@dataclass
class PinggyConfig:
    """Configuration for Pinggy tunnel."""

    persistent_url: str  # e.g., "bjfqkhfxtx.a.pinggy.link"
    ssh_command: str  # Full SSH command for the tunnel
    local_port: int = 8000  # Local vLLM port to tunnel
    health_check_timeout: int = 60  # Seconds to wait for tunnel to be ready
    health_check_interval: int = 2  # Seconds between health checks


@dataclass
class PinggyTunnel:
    """Manages a Pinggy tunnel process.

    The tunnel exposes a local port (typically vLLM on 8000) via Pinggy's
    public HTTPS endpoint. This allows cloud-based containers (Daytona, Modal)
    to reach the vLLM server running on an HPC compute node.
    """

    config: PinggyConfig
    _process: Optional[subprocess.Popen] = field(default=None, repr=False)
    _log_file: Optional[Any] = field(default=None, repr=False)
    log_path: Optional[Path] = None

    @property
    def public_endpoint(self) -> str:
        """Get the public HTTPS endpoint URL (OpenAI-compatible /v1 path)."""
        return f"https://{self.config.persistent_url}/v1"

    @property
    def public_base_url(self) -> str:
        """Get the public HTTPS base URL (without /v1)."""
        return f"https://{self.config.persistent_url}"

    @property
    def is_running(self) -> bool:
        """Check if the tunnel process is running."""
        return self._process is not None and self._process.poll() is None

    def start(self) -> str:
        """Start the Pinggy tunnel and return the public endpoint.

        Returns:
            The public HTTPS endpoint URL (e.g., https://xxx.a.pinggy.link/v1)

        Raises:
            RuntimeError: If tunnel fails to start or health check fails
        """
        if self._process is not None:
            print(f"Pinggy tunnel already running at {self.public_endpoint}")
            return self.public_endpoint

        print(f"=== Starting Pinggy Tunnel ===")
        print(f"  Persistent URL: {self.config.persistent_url}")
        print(f"  Local port: {self.config.local_port}")
        print(f"==============================")

        # Open log file if path provided
        if self.log_path:
            self.log_path.parent.mkdir(parents=True, exist_ok=True)
            self._log_file = open(self.log_path, "w", buffering=1)
            stdout_dest = self._log_file
            stderr_dest = subprocess.STDOUT
        else:
            stdout_dest = subprocess.DEVNULL
            stderr_dest = subprocess.DEVNULL

        # Parse and execute the SSH command
        # The command is typically a shell loop, so we run it via bash
        cmd = ["bash", "-c", self.config.ssh_command]

        try:
            self._process = subprocess.Popen(
                cmd,
                stdout=stdout_dest,
                stderr=stderr_dest,
                # Don't let the tunnel inherit our signal handlers
                preexec_fn=os.setpgrp if hasattr(os, "setpgrp") else None,
            )
        except Exception as e:
            raise RuntimeError(f"Failed to start Pinggy tunnel: {e}")

        print(f"  Started Pinggy tunnel (PID: {self._process.pid})")
        if self.log_path:
            print(f"  Log file: {self.log_path}")

        # Wait for tunnel to be healthy
        self._wait_for_healthy()

        print(f"=== Pinggy Tunnel Ready ===")
        print(f"  Public endpoint: {self.public_endpoint}")
        print(f"===========================")

        return self.public_endpoint

    def stop(self) -> None:
        """Stop the Pinggy tunnel."""
        if self._process is None:
            return

        print("Stopping Pinggy tunnel...")

        # Try graceful termination first
        try:
            # Kill the process group to ensure all child processes are terminated
            if hasattr(os, "killpg"):
                try:
                    os.killpg(os.getpgid(self._process.pid), signal.SIGTERM)
                except (ProcessLookupError, PermissionError):
                    pass
            else:
                self._process.terminate()

            self._process.wait(timeout=10)
            print("  Pinggy tunnel stopped gracefully")
        except subprocess.TimeoutExpired:
            print("  Pinggy tunnel not responding, killing...")
            if hasattr(os, "killpg"):
                try:
                    os.killpg(os.getpgid(self._process.pid), signal.SIGKILL)
                except (ProcessLookupError, PermissionError):
                    pass
            else:
                self._process.kill()
            self._process.wait()

        self._process = None

        # Close log file
        if self._log_file:
            self._log_file.close()
            self._log_file = None

    def _wait_for_healthy(self) -> None:
        """Wait for the Pinggy tunnel to be ready by health checking the public URL."""
        health_url = f"{self.public_base_url}/v1/models"
        print(f"  Waiting for tunnel to be ready (checking {health_url})...")

        start_time = time.time()
        last_error = None

        while time.time() - start_time < self.config.health_check_timeout:
            # Check if process died
            if self._process and self._process.poll() is not None:
                raise RuntimeError(
                    f"Pinggy tunnel process exited unexpectedly (code {self._process.returncode}). "
                    f"Check logs at {self.log_path}"
                )

            try:
                req = urllib.request.Request(health_url, method="GET")
                req.add_header("User-Agent", "Harbor-Pinggy-HealthCheck/1.0")
                with urllib.request.urlopen(req, timeout=10) as response:
                    if response.status == 200:
                        elapsed = time.time() - start_time
                        print(f"  Tunnel healthy after {elapsed:.1f}s")
                        return
            except (urllib.error.URLError, urllib.error.HTTPError, OSError) as e:
                last_error = e

            time.sleep(self.config.health_check_interval)

        raise RuntimeError(
            f"Pinggy tunnel health check failed after {self.config.health_check_timeout}s. "
            f"Last error: {last_error}"
        )

    def __enter__(self) -> "PinggyTunnel":
        """Context manager entry - start the tunnel."""
        self.start()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb) -> None:
        """Context manager exit - stop the tunnel."""
        self.stop()


def needs_pinggy_tunnel(agent_name: Optional[str], env_type: Optional[str]) -> bool:
    """Determine if Pinggy tunnel is needed based on agent and environment.

    Returns True if:
    - Agent is an installed agent (not terminus-2 which runs in-process)
    - Environment is a cloud backend (daytona, modal) that can't reach local network

    Args:
        agent_name: Name of the agent (e.g., "openhands", "terminus-2")
        env_type: Harbor environment type (e.g., "daytona", "docker", "apptainer")

    Returns:
        True if Pinggy tunnel is needed
    """
    # Terminus-2 runs in-process with direct LLM access, doesn't need tunnel
    if agent_name and agent_name.lower() in ("terminus-2", "terminus_2", "terminus2"):
        return False

    # Local container backends have direct network access to vLLM
    local_backends = ("docker", "apptainer", "singularity", "local")
    if env_type and env_type.lower() in local_backends:
        return False

    # Cloud backends (daytona, modal) need tunnel to reach local vLLM
    return True


def build_pinggy_endpoint_meta(pinggy_url: str) -> Dict[str, str]:
    """Build endpoint metadata dict from a Pinggy tunnel URL.

    Args:
        pinggy_url: Pinggy public URL (e.g., "https://xxx.a.pinggy.link")

    Returns:
        Dict with 'api_base' and 'metrics_endpoint' keys
    """
    url = pinggy_url.rstrip("/")

    # Ensure we have the /v1 suffix for api_base
    if url.endswith("/v1"):
        api_base = url
        base_url = url[:-3]
    else:
        api_base = f"{url}/v1"
        base_url = url

    return {
        "api_base": api_base,
        "metrics_endpoint": f"{base_url}/metrics",
    }


def create_pinggy_config_from_args(
    persistent_url: Optional[str],
    ssh_command: Optional[str],
    local_port: int = 8000,
) -> Optional[PinggyConfig]:
    """Create PinggyConfig from CLI arguments.

    Args:
        persistent_url: Pinggy persistent URL (e.g., "bjfqkhfxtx.a.pinggy.link")
        ssh_command: Full SSH command for the tunnel
        local_port: Local port to tunnel (default: 8000)

    Returns:
        PinggyConfig if both URL and command provided, None otherwise
    """
    if not persistent_url or not ssh_command:
        return None

    return PinggyConfig(
        persistent_url=persistent_url,
        ssh_command=ssh_command,
        local_port=local_port,
    )


# Default Pinggy configuration (can be overridden via CLI)
DEFAULT_PINGGY_SSH_COMMAND = (
    "while true; do "
    "ssh -p 443 -R0:localhost:8000 -L4300:localhost:4300 "
    "-o StrictHostKeyChecking=no -o ServerAliveInterval=30 "
    "oVxgHq855Ln@pro.pinggy.io; "
    "sleep 10; "
    "done"
)


if __name__ == "__main__":
    # CLI for testing
    import argparse

    parser = argparse.ArgumentParser(description="Test Pinggy tunnel")
    parser.add_argument(
        "--persistent-url",
        default="bjfqkhfxtx.a.pinggy.link",
        help="Pinggy persistent URL",
    )
    parser.add_argument(
        "--ssh-command",
        default=DEFAULT_PINGGY_SSH_COMMAND,
        help="SSH command for tunnel",
    )
    parser.add_argument(
        "--local-port",
        type=int,
        default=8000,
        help="Local port to tunnel",
    )
    parser.add_argument(
        "--timeout",
        type=int,
        default=60,
        help="Health check timeout in seconds",
    )

    args = parser.parse_args()

    config = PinggyConfig(
        persistent_url=args.persistent_url,
        ssh_command=args.ssh_command,
        local_port=args.local_port,
        health_check_timeout=args.timeout,
    )

    print(f"Testing Pinggy tunnel to {config.persistent_url}")
    print(f"Press Ctrl+C to stop")

    try:
        with PinggyTunnel(config) as tunnel:
            print(f"\nTunnel active at: {tunnel.public_endpoint}")
            print("Waiting... (Ctrl+C to stop)")
            while True:
                time.sleep(1)
    except KeyboardInterrupt:
        print("\nStopping...")

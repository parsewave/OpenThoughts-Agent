from __future__ import annotations

import textwrap
from pathlib import Path
from typing import Any, Callable, Optional

import yaml

from hpc.arguments import LlamaFactoryArgs
from hpc.data_argument_keys import DATA_ARGUMENT_KEYS


def apply_mca_training_template(
    exp_args: dict,
    hpc,
    *,
    update_exp_args_fn: Callable[[dict, dict], dict],
) -> dict:
    """Point training jobs at the MCA-specific sbatch template when requested."""

    mca_template = Path(__file__).parent / "sbatch" / f"{hpc.name.lower()}_train_mca.sbatch"
    if mca_template.exists():
        return update_exp_args_fn(
            exp_args,
            {
                "train_sbatch_filename": mca_template.name,
                "train_sbatch_path": str(mca_template),
            },
        )

    print(
        f"Warning: MCA sbatch template {mca_template} not found for cluster {hpc.name}; using default template."
    )
    return exp_args


def build_training_parameters_link(hub_model_id: Optional[str]) -> Optional[str]:
    if not hub_model_id:
        return None
    hub_model_id = hub_model_id.strip("/")
    return f"https://huggingface.co/{hub_model_id}/blob/main/config.json"


def _escape_template_braces(text: str) -> str:
    result: list[str] = []
    i = 0
    length = len(text)
    while i < length:
        char = text[i]
        if char == "$" and i + 1 < length and text[i + 1] == "{":
            j = i + 2
            while j < length and text[j] != "}":
                j += 1
            if j < length:
                result.append(text[i : j + 1])
                i = j + 1
                continue
        if char == "{":
            result.append("{{")
            i += 1
        elif char == "}":
            result.append("}}")
            i += 1
        else:
            result.append(char)
            i += 1
    return "".join(result)


def _normalize_strategy_value(value: Any) -> Optional[str]:
    if value is None:
        return None
    if isinstance(value, str):
        normalized = value.strip()
        if not normalized or normalized.lower() in {"none", "null", "false"}:
            return None
        return normalized
    return value


def _detect_distributed_strategy(exp_args: dict) -> Optional[str]:
    if _normalize_strategy_value(exp_args.get("deepspeed")):
        return "deepspeed"
    fsdp_cfg = exp_args.get("fsdp_config")
    if isinstance(fsdp_cfg, dict) and fsdp_cfg:
        return "fsdp"
    if _normalize_strategy_value(exp_args.get("fsdp")):
        return "fsdp"
    return None


def resolve_mixed_precision_setting(exp_args: dict) -> str:
    if _normalize_strategy_value(exp_args.get("fp8")):
        return "fp8"
    if exp_args.get("bf16") or exp_args.get("pure_bf16"):
        return "bf16"
    if exp_args.get("fp16"):
        return "fp16"
    return "no"


def _render_fsdp_config_block(exp_args: dict) -> str:
    fsdp_cfg = exp_args.get("fsdp_config")
    if isinstance(fsdp_cfg, dict) and fsdp_cfg:
        rendered = yaml.safe_dump(fsdp_cfg, sort_keys=False).strip()
    else:
        rendered = "\n".join(
            [
                "fsdp_version: 2",
                "fsdp_state_dict_type: SHARDED_STATE_DICT",
                "fsdp_offload_params: false",
                "fsdp_reshard_after_forward: true",
                "fsdp_cpu_ram_efficient_loading: true",
            ]
        )
    return textwrap.indent(rendered, "  ")


def build_accelerate_config_block(exp_args: dict) -> str:
    strategy = _detect_distributed_strategy(exp_args)
    if not strategy:
        return ""

    lines: list[str] = []
    accelerate_header = 'ACCELERATE_CONFIG_FILE="$TMP_DIR/${SLURM_JOB_ID}_accelerate_config.yaml.autogenerated"'
    if strategy == "deepspeed":
        ds_config_path = str(exp_args.get("deepspeed") or "").strip()
        lines.append(f"DEEPSPEED_CONFIG_FILE={ds_config_path}")
        lines.append(accelerate_header)
        lines.append("export ACCELERATE_CONFIG_FILE")
        lines.append('cat << EOT > "$ACCELERATE_CONFIG_FILE"')
        lines.append("# WARNING: auto-generated by launcher")
        lines.append("compute_environment: LOCAL_MACHINE")
        lines.append("deepspeed_config:")
        lines.append("  deepspeed_multinode_launcher: standard")
        lines.append("  deepspeed_config_file: $DEEPSPEED_CONFIG_FILE")
        lines.append("  zero3_init_flag: true")
        lines.append("distributed_type: DEEPSPEED")
        lines.append("fsdp_config:")
        lines.append("machine_rank: 0")
        lines.append("main_process_ip: $MASTER_ADDR")
        lines.append("main_process_port: $MASTER_PORT")
        lines.append("main_training_function: main")
        lines.append("num_machines: $SLURM_NNODES")
        lines.append("num_processes: $NUM_GPUS")
        lines.append("use_cpu: false")
        lines.append("EOT")
    elif strategy == "fsdp":
        mixed_precision = resolve_mixed_precision_setting(exp_args)
        fsdp_config_lines = _render_fsdp_config_block(exp_args)
        lines.append(accelerate_header)
        lines.append("export ACCELERATE_CONFIG_FILE")
        lines.append('cat << EOT > "$ACCELERATE_CONFIG_FILE"')
        lines.append("# WARNING: auto-generated by launcher")
        lines.append("compute_environment: LOCAL_MACHINE")
        lines.append("distributed_type: FSDP")
        lines.append(f"mixed_precision: {mixed_precision}")
        lines.append("fsdp_config:")
        if fsdp_config_lines:
            lines.extend(fsdp_config_lines.splitlines())
        lines.append("machine_rank: 0")
        lines.append("main_process_ip: $MASTER_ADDR")
        lines.append("main_process_port: $MASTER_PORT")
        lines.append("main_training_function: main")
        lines.append("num_machines: $SLURM_NNODES")
        lines.append("num_processes: $NUM_GPUS")
        lines.append("use_cpu: false")
        lines.append("EOT")

    block = "\n".join(lines).strip()
    if not block:
        return ""
    return _escape_template_braces(block) + "\n"


def _normalize_deepspeed_path(ds_val: str) -> str:
    if not isinstance(ds_val, str):
        return ds_val
    mapping = {
        "dcft/train/zero3.json": "dcft/train/llamafactory/examples/deepspeed/ds_z3_config.json",
        "dcft/train/zero3_offload.json": "dcft/train/llamafactory/examples/deepspeed/ds_z3_offload_config.json",
        "dcft/train/zero2.json": "dcft/train/llamafactory/examples/deepspeed/ds_z2_config.json",
    }
    if ds_val in mapping:
        return mapping[ds_val]
    for old, new in mapping.items():
        if ds_val.endswith(old) or old in ds_val:
            return ds_val.replace(old, new)
    return ds_val


def ensure_deepspeed_config(base_config: dict, exp_args: dict) -> dict:
    """Ensure DeepSpeed settings exist and point at canonical config paths."""

    default_ds = LlamaFactoryArgs.__dataclass_fields__["deepspeed"].default
    if not base_config.get("deepspeed"):
        base_config["deepspeed"] = exp_args.get("deepspeed", default_ds) or default_ds

    if isinstance(base_config.get("deepspeed"), str):
        normalized = _normalize_deepspeed_path(base_config["deepspeed"])
        if normalized != base_config["deepspeed"]:
            print(f"Normalized deepspeed path: {base_config['deepspeed']} -> {normalized}")
            base_config["deepspeed"] = normalized
    return base_config


def maybe_compute_gradient_accumulation(base_config: dict, exp_args: dict) -> dict:
    num_nodes = int(exp_args.get("num_nodes"))
    num_gpus = int(exp_args.get("gpus_per_node"))
    raw_global_batch_size = exp_args.pop("global_batch_size", None)
    if raw_global_batch_size is None:
        raw_global_batch_size = base_config.pop("global_batch_size", None)
    else:
        base_config.pop("global_batch_size", None)

    if raw_global_batch_size is None:
        print("\nSkipping automatic gradient accumulation calculation because global_batch_size was not provided.")
        return base_config

    try:
        global_batch_size = int(raw_global_batch_size)
    except (TypeError, ValueError) as exc:
        raise ValueError(
            f"Expected integer-like global_batch_size, got {raw_global_batch_size!r}"
        ) from exc

    total_gpu_count = num_nodes * num_gpus

    def _int_config_value(key: str, default: int = 1) -> int:
        raw_value = base_config.get(key, default)
        try:
            return int(raw_value)
        except (TypeError, ValueError) as exc:
            raise ValueError(
                f"Expected integer-like value for {key}, got {raw_value!r}"
            ) from exc

    tensor_model_parallel_size = _int_config_value("tensor_model_parallel_size", 1)
    pipeline_model_parallel_size = _int_config_value("pipeline_model_parallel_size", 1)
    expert_model_parallel_size = _int_config_value("expert_model_parallel_size", 1)

    model_parallel_world_size = (
        tensor_model_parallel_size
        * pipeline_model_parallel_size
        * expert_model_parallel_size
    )
    if model_parallel_world_size <= 0:
        raise ValueError(
            f"Model parallel world size must be positive; got {model_parallel_world_size}"
        )

    if total_gpu_count % model_parallel_world_size != 0:
        print(
            f"Warning: total GPU count ({total_gpu_count}) is not divisible by model parallel size "
            f"({model_parallel_world_size}). Rounding down data parallel replicas."
        )
    data_parallel_replicas = max(total_gpu_count // model_parallel_world_size, 1)

    per_device_train_batch_size = base_config.get("per_device_train_batch_size", 1)
    try:
        per_device_train_batch_size = max(int(per_device_train_batch_size), 1)
    except (TypeError, ValueError) as exc:
        raise ValueError(
            f"Expected integer-like per_device_train_batch_size, got {per_device_train_batch_size!r}"
        ) from exc

    effective_batch_denom = per_device_train_batch_size * data_parallel_replicas
    if effective_batch_denom == 0:
        raise ValueError("Effective batch denominator resolved to zero.")

    gradient_accumulation_steps = global_batch_size // effective_batch_denom
    if gradient_accumulation_steps == 0 or (
        gradient_accumulation_steps * effective_batch_denom != global_batch_size
    ):
        raise ValueError(
            "Global batch size is not divisible by per-device batch * data-parallel replicas. "
            f"global_batch_size={global_batch_size}, per_device_train_batch_size={per_device_train_batch_size}, "
            f"data_parallel_replicas={data_parallel_replicas}"
        )

    base_config["gradient_accumulation_steps"] = gradient_accumulation_steps
    base_config["per_device_train_batch_size"] = per_device_train_batch_size
    print(f"\nCalculated based on {num_nodes} nodes, {num_gpus} GPUs per node, and global batch size {global_batch_size}:")
    print(f"data_parallel_replicas: {data_parallel_replicas}")
    print(f"per_device_train_batch_size: {per_device_train_batch_size}")
    print(f"gradient_accumulation_steps: {gradient_accumulation_steps}")
    return base_config


def apply_data_argument_overrides(base_config: dict, exp_args: dict) -> None:
    for tag in DATA_ARGUMENT_KEYS:
        if tag in exp_args:
            tag_value = exp_args[tag]
            if tag_value is not None:
                base_config[tag] = tag_value

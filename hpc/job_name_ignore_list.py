"""
Arguments that should be ignored when deriving autogenerated job names.

These are typically infrastructure toggles, resource parameters, or noisy flags
that do not contribute to the logical identity of a job. Keeping them in a
central list avoids duplication between launch entry points.
"""

JOB_NAME_IGNORE_KEYS: list[str] = [
    "name",
    "dotenv_filename",
    "dotenv_path",
    "train_sbatch_filename",
    "hostname",
    "deepspeed",
    "train_config_path_out",
    "train_config_path",
    "hub_model_id",
    "hostname_pattern",
    "num_nodes",
    "gpus_per_node",
    "cpus_per_task",
    "time_limit",
    "output_dir",
    "experiments_dir",
    "train_sbatch_path",
    "train_sbatch_path_out",
    "partition",
    "account",
    "gpus_type",
    "total_partition_nodes",
    "internet_node",
    "mem_per_node",
    "cpus_per_node",
    "cpus_per_gpu",
    "formatting",
    "prompt_column",
    "query_column",
    "response_column",
    "history_column",
    "role_tag",
    "user_tag",
    "content_tag",
    "assistant_tag",
    "messages",
    "system",
    "mix_strategy",
    "interleave_probs",
    "streaming",
    "buffer_size",
    "max_samples",
    "val_size",
    "eval_on_each_dataset",
    "disable_shuffling",
    "qos",
    "max_restarts",
    "pretokenize",
    "pretok_large",
    "dry_run",
    # Datagen/VLLM-specific args should not affect training job names
    "job_type",
    "job_creator",
    "datagen_script",
    "datagen_target_repo",
    "datagen_config",
    "datagen_input_dir",
    "datagen_healthcheck_interval",
    "datagen_extra_args",
    "datagen_engine",
    "datagen_backend",
    "datagen_model",
    "datagen_max_tokens",
    "datagen_ray_port",
    "datagen_api_port",
    "datagen_output_dir",
    "datagen_wait_for_endpoint",
    "pinggy_persistent_url",
    "pinggy_ssh_command",
    "pinggy_debugger_url",
    "use_mca",
    "task_type",
    "vllm_model_path",
    "vllm_num_replicas",
    "vllm_tensor_parallel_size",
    "vllm_pipeline_parallel_size",
    "vllm_custom_model_name",
    "vllm_endpoint_json_path",
    "vllm_server_time_limit",
    "vllm_hf_overrides",
    "vllm_use_deep_gemm",
    "vllm_max_num_seqs",
    "vllm_gpu_memory_utilization",
    "vllm_enable_expert_parallel",
    "vllm_swap_space",
    "vllm_max_seq_len_to_capture",
    "vllm_max_model_len",
    "vllm_trust_remote_code",
    "vllm_disable_log_requests",
    "vllm_enable_auto_tool_choice",
    "vllm_tool_call_parser",
    "vllm_reasoning_parser",
    "sandbox_cpu",
    "sandbox_memory_gb",
    "sandbox_disk_gb",
    "sandbox_gpu",
    # Noisy toggles that shouldn't impact identity
    "overwrite_output_dir",
    "enable_task_gen",
    "enable_trace_gen",
    "disable_verification",
    "trace_script",
    "trace_target_repo",
    "tasks_input_path",
    "trace_use_gpu",
    "trace_engine",
    "trace_backend",
    "trace_harbor_config",
    "chunk_size",
    "trace_model",
    "trace_agent_name",
    "trace_agent_kwargs",
    "trace_n_concurrent",
    "trace_env",
    "trace_eval_only",
    "trace_export_subagents",
    "push_to_hub",
    "harbor_dataset",
    # Upload toggles (don't affect job identity)
    "upload_to_database",
    "upload_username",
    "upload_error_mode",
    "upload_hf_repo",
    "upload_hf_private",
    "upload_hf_episodes",
    "upload_forced_update",
    # Timeout toggles
    "trace_agent_timeout_sec",
    "trace_verifier_timeout_sec",
    "consolidate_input",
    "consolidate_output_repo",
    "consolidate_base_repo",
    "consolidate_workdir",
    "consolidate_commit_message",
    "dependency",
    # RL environment toggles
    "rl_use_conda",
    "rl_conda_env",
]

# Harbor eval configuration (16 concurrency, OpenHands, 131k context, TOOL CALLING ENABLED)
#
# This config enables native OpenHands tool calling via the OpenAI function calling API.
# Use this with vLLM configs that have enable_auto_tool_choice: true
#
# Key difference from standard openhands configs:
#   disable_tool_calls: false  (enables native function calling)
#
# Usage:
#   python -m hpc.launch \
#       --job_type eval \
#       --vllm_serve_config hpc/datagen_yaml/nemotron_nano_30b_vllm_serve_32k_toolcall.yaml \
#       --harbor_yaml hpc/harbor_yaml/trace_16concurrency_openhands_eval_ctx131k_toolcall.yaml \
#       ...

job_name: default-eval-job
jobs_dir: trace_jobs
n_attempts: 3
timeout_multiplier: 1.0
debug: false

orchestrator:
  type: local
  n_concurrent_trials: 16
  quiet: false
  plain_output: true
  adaptive_concurrency:
    enabled: false
    algorithm: gradient2
    min_limit:
    max_limit:
    metrics_endpoint:
    metrics_timeout_sec: 10.0
    poll_interval_sec: 120.0
    window_size: 5
    queue_p95_drop_threshold:
    algorithm_kwargs: {}
  retry:
    max_retries: 100
    include_exceptions:
    exclude_exceptions:
    - AgentTimeoutError
    - VerifierTimeoutError
    wait_multiplier: 2.0
    min_wait_sec: 1.0
    max_wait_sec: 90.0
  kwargs: {}

environment:
  type: daytona
  force_build: true
  delete: true
  override_cpus: 1
  override_memory_mb: 2048
  override_storage_mb: 2048
  kwargs: {}

verifier:
  override_timeout_sec:
  max_timeout_sec:
  disable: false

metrics: []

agents:
- name: openhands
  import_path:
  model_name: placeholder/override-at-runtime
  max_timeout_sec:
  override_setup_timeout_sec: 600
  kwargs:
    # IMPORTANT: Tool calling ENABLED for native function calling
    # This requires the vLLM server to have enable_auto_tool_choice: true
    # and an appropriate tool_call_parser (e.g., hermes for Nemotron)
    disable_tool_calls: false

    collect_rollout_details: false
    collect_engine_metrics: false
    metrics_endpoint: https://replace-with-vllm-host/metrics
    metrics_timeout_sec: 10
    model_info:
      max_input_tokens: 131072
      max_output_tokens: 16384
      input_cost_per_token: 0
      output_cost_per_token: 0

    trajectory_config:
      raw_content: false  # Use events folder (structured tool calls) instead of raw completions
      linear_history: true

datasets:
- path: /replace/with/tasks/path

tasks: []

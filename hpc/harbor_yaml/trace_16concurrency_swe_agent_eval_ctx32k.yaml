# Harbor eval configuration for SWE-Agent with hosted vLLM (16 concurrency, 32k context).
# For use with Pinggy tunnels to expose vLLM endpoints to installed agents.
# This is the full SWE-agent scaffold that SERA was trained on.

job_name: swe-agent-eval-job
jobs_dir: trace_jobs
n_attempts: 3
timeout_multiplier: 1.0
debug: false

orchestrator:
  type: local
  n_concurrent_trials: 16
  quiet: false
  plain_output: true
  adaptive_concurrency:
    enabled: false
    algorithm: gradient2
    min_limit:
    max_limit:
    metrics_endpoint:
    metrics_timeout_sec: 10.0
    poll_interval_sec: 120.0
    window_size: 5
    queue_p95_drop_threshold:
    algorithm_kwargs: {}
  retry:
    max_retries: 10
    include_exceptions:
    exclude_exceptions:
    - AgentTimeoutError
    - VerifierTimeoutError
    - SandboxBuildFailedError
    wait_multiplier: 2.0
    min_wait_sec: 1.0
    max_wait_sec: 90.0
  kwargs: {}

environment:
  type: daytona
  force_build: true
  delete: true
  override_cpus: 1
  override_memory_mb: 2048
  override_storage_mb: 2048
  kwargs: {}

verifier:
  override_timeout_sec: 1800
  max_timeout_sec: 900
  disable: false

metrics: []

agents:
- name: swe-agent
  import_path:
  model_name: hosted_vllm/placeholder-override-at-runtime
  max_timeout_sec:
  kwargs:
    model_info:
      max_input_tokens: 32768
      max_output_tokens: 8192
      input_cost_per_token: 0
      output_cost_per_token: 0

datasets:
- path: /replace/with/tasks/path

tasks: []

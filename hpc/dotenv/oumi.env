export WANDB_ENTITY=dogml
export WANDB_PROJECT=OpenThoughts-Agent
export DCFT=/home/benjamin/OpenThoughts-Agent
export HF_HUB_CACHE=$SCRATCH/hub
export CHECKPOINTS_DIR=$SCRATCH/checkpoints
export MODELS_DIR=$HF_HUB_CACHE
export DATASETS_DIR=$HF_HUB_CACHE
export TOKENIZED_DATASETS_DIR=$SCRATCH/tokenized_datasets
export DCFT_CONDA=$HOME/miniconda3
export DCFT_ACTIVATE_ENV="source $HOME/miniconda3/bin/activate llama-factory && export PYTHONPATH=${DCFT_PRIVATE:-$DCFT}${PYTHONPATH:+:$PYTHONPATH}"
export VLLM_ACTIVATE_ENV="source $HOME/miniconda3/bin/activate vllm && export PYTHONPATH=${DCFT_PRIVATE:-$DCFT}${PYTHONPATH:+:$PYTHONPATH}"
export VLLM_CACHE_ROOT=$SCRATCH/vllm
export PINGGY_PERSISTENT_URL=xcdppeurjb.a.pinggy.link
export PINGGY_DEBUGGER_URL=http://localhost:4300/
export PINGGY_SSH_COMMAND='while true; do ssh -p 443 -R0:localhost:8000 -L4300:localhost:4300 -o StrictHostKeyChecking=no -o ServerAliveInterval=30 i7KxKVvGYVs@pro.pinggy.io; sleep 10; done'
export DC_AGENT_SECRET_ENV="/home/benjamin/.env_vars"
export GCS_CREDENTIALS_PATH="/path/to/credentials.json"
export PYTORCH_CUDA_ALLOW_TF32=1          # turns on TF32 for GEMM (same as torch.set_float32_matmul_precision("high"))
export PYTORCH_CUDNN_ALLOW_TF32=1         # optional, lets cuDNN kernels use TF32 too
# SkyRL home directory (clone from https://github.com/penfever/SkyRL.git)
export SKYRL_HOME=$SCRATCH/SkyRL
# Keep the repo importable even if Python strips the working directory from sys.path.
# Include SKYRL_HOME/skyrl-train for examples/terminal_bench entrypoints
export PYTHONPATH="${SKYRL_HOME}/skyrl-train:${DCFT_PRIVATE:-$DCFT}${PYTHONPATH:+:$PYTHONPATH}"

# SkyRL Terminal Bench Configuration
# This YAML replaces 50+ Hydra CLI arguments for terminal-bench RL training
#
# Usage:
#   python -m hpc.launch \
#       --job_type rl \
#       --rl_config terminal_bench.yaml \
#       --job_name my_run \
#       --train_data '["mlfoundations-dev/dataset"]' \
#       --model_path Qwen/Qwen2.5-7B-Instruct

# SkyRL entrypoint module
entrypoint: examples.terminal_bench.entrypoints.main_tbench

# Hydra config groups (+ prefix in CLI)
config_groups:
  terminal_bench_config: terminal_bench

# Terminal bench / agentic environment settings
terminal_bench:
  # trials_dir: Directory for Harbor trial artifacts (derived from experiments_dir if null)
  trials_dir: null

  # Harbor configuration - schema-driven mapping to TrialConfig
  # See examples/terminal_bench/harbor_config.py for full list of supported fields.
  # Unknown fields will generate warnings (typo protection + version compatibility).
  harbor:
    # ==========================================================================
    # Agent settings (maps to Harbor AgentConfig)
    # ==========================================================================
    # Agent name - must be a valid Harbor AgentName (e.g., terminus-2, oracle)
    name: terminus-2
    # Max agent-environment turns before Harbor forces termination
    max_episodes: 32
    # Enable summarization to compress long histories
    # IMPORTANT: This helps keep prompts under budget as conversations grow
    enable_summarize: true
    # Store full message history for trajectory reconstruction
    store_all_messages: true

    # Agent timeout overrides
    override_timeout_sec: 240        # Agent execution timeout (seconds)
    # override_setup_timeout_sec: 120  # Agent setup timeout
    # max_timeout_sec: 1800          # Cap timeout (useful for runaway tasks)

    # ==========================================================================
    # Environment settings (maps to Harbor EnvironmentConfig)
    # ==========================================================================
    # Sandbox resources - adequate for most agentic tasks
    override_cpus: 1
    override_memory_mb: 1024
    override_storage_mb: 1024
    # override_gpus: 0              # GPU allocation per sandbox
    # environment_type: daytona     # Environment backend (daytona, docker, modal)

    # ==========================================================================
    # Trial-level settings (maps to Harbor TrialConfig)
    # ==========================================================================
    # timeout_multiplier: 1.0       # Multiply all timeouts by this factor

    # ==========================================================================
    # Verifier settings (maps to Harbor VerifierConfig)
    # ==========================================================================
    # verifier_disable: false       # Disable verification (for debugging)
    # verifier_override_timeout_sec: 300  # Override verifier timeout

    # ==========================================================================
    # Retry settings (maps to Harbor RetryConfig for QueueOrchestrator)
    # ==========================================================================
    max_retries: 2                 # Max retry attempts per trial
    min_wait_sec: 1.0              # Initial backoff delay (seconds)
    max_wait_sec: 60.0             # Maximum backoff delay
    wait_multiplier: 2.0           # Exponential backoff multiplier

    # Exception filtering - don't retry permanent failures
    # Note: ContextLengthExceededError not excluded since enable_summarize=true
    exclude_exceptions:
      - AgentTimeoutError
      - VerifierTimeoutError
      - RewardFileNotFoundError
      - RewardFileEmptyError
      - VerifierOutputParseError

    # ==========================================================================
    # Orchestrator settings (QueueOrchestrator concurrency control)
    # ==========================================================================
    n_concurrent_trials: 16        # Number of parallel trial workers

  # Model info for Harbor's hosted_vllm validation (token limits and costs)
  model_info:
    max_input_tokens: 2048
    max_output_tokens: 40000

# Trainer configuration
trainer:
  strategy: fsdp2
  algorithm:
    advantage_estimator: grpo
    use_kl_loss: true
  epochs: 10
  # IMPORTANT: train_batch_size must be >= total GPUs (data parallel size)
  # Override with --skyrl_override trainer.train_batch_size=N if needed
  train_batch_size: 16
  eval_batch_size: 128
  eval_interval: 20
  eval_before_train: false
  update_epochs_per_batch: 1
  policy_mini_batch_size: 8
  micro_forward_batch_size_per_gpu: 1
  micro_train_batch_size_per_gpu: 1
  ckpt_interval: 5
  max_prompt_length: 999999
  resume_mode: latest
  project_name: dc-agent
  log_level: INFO  # SkyRL logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
  # Paths derived from experiments_dir/job_name if null
  run_name: null
  ckpt_path: null
  export_path: null

  policy:
    optimizer_config:
      lr: 1.0e-6
      weight_decay: 0.01
      adam_betas: [0.9, 0.999]
      max_grad_norm: 1.0

  ref:
    fsdp_config:
      cpu_offload: true

  # Model placement - derived from CLI args (--num_nodes, --gpus_per_node)
  placement:
    colocate_all: true
    policy_num_nodes: null
    ref_num_nodes: null
    policy_num_gpus_per_node: null
    ref_num_gpus_per_node: null

# Generator (vLLM inference)
generator:
  backend: vllm
  # Computed: (num_nodes * gpus_per_node) / tensor_parallel_size
  num_inference_engines: null
  inference_engine_tensor_parallel_size: 1
  n_samples_per_prompt: 4
  eval_n_samples_per_prompt: 8
  gpu_memory_utilization: 0.85
  run_engines_locally: true
  weight_sync_backend: nccl
  async_engine: true
  batched: true
  enable_http_endpoint: true
  append_eos_token_after_stop_str_in_multi_turn: true
  sampling_params:
    max_generate_length: 30720
  # Engine initialization kwargs - passed directly to vLLM/SGLang engine
  # WARNING: Many kwargs are set by SkyRL internally (trust_remote_code, enforce_eager, etc.)
  # The launcher validates this at parse time and will error with a full list if you set forbidden keys.
  # SAFE TO SET: custom_chat_template_*, kv_cache_dtype, quantization, cpu_offload_gb, etc.
  engine_init_kwargs:
    custom_chat_template_chat_completion_path: chat_templates/qwen3_thinking_acc.jinja2

# Data paths (set via CLI --train_data, --val_data)
data:
  train_data: []
  val_data: []

{
  "model_path": "QuantTrio/GLM-4.6-AWQ",
  "num_nodes": 4,
  "gpus_per_node": 1,
  "tensor_parallel_size": 4,
  "pipeline_parallel_size": 1,
  "enable_expert_parallel": true,
  "dtype": "bfloat16",
  "trust_remote_code": true,
  "block_size": 16,
  "swap_space_gb": 4,
  "enable_chunked_prefill": true,
  "max_num_partial_prefills": 1,
  "max_model_len": 113000,
  "name": "4node_tp4_pp1_fp8kv_113k",
  "gpu_memory_utilization": 0.92,
  "max_num_batched_tokens": 32768,
  "max_num_seqs": 128,
  "kv_cache_dtype": "fp8",
  "enable_prefix_caching": true,
  "all2all_backend": "pplx",
  "enable_eplb": false
}
